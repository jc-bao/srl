# wandb
wandb: false
resume_mode: load_only 
wid: 269v0q4f
project: TD3_debug 
name: handover_default 

# seed 
random_seed: 0

# replay
her_rate: 0.8
her_decay: 0.0
g_random_relabel_rate: 1.0
ag_random_relabel_rate: 1.0
if_use_per: false
buffer_size: 4000
dropout_early_termin: false

# env_params
env_name: 'FrankaPNP-v0'
env_params: null
env_kwargs:
  num_envs: 1
  num_cameras: 0
  num_robots: 2
  num_goals: 1
  base_steps: 25 # wired, need investigation
  goal_space: [0.3,0.3,0.2]
  os_rate: 0.5
  table_gap: 0.2
  inhand_rate: 0.0
  headless: false
reward_scale: 1
extra_info_dim: 0 # extra info get from agent

# network
act_net: Actor
critic_net: CriticTwin
net_dim: 256
net_layer: 4
shared_net_layer: 3
n_head: 4
net_type: attn
if_act_target: true
if_cri_target: true
gpu_id: 0

# algorithm
agent_name: AgentTD3
max_collect_steps: !!float 1e9
reuse: 10
steps_per_rollout: null 
updates_per_rollout: null # calulate with reuse
batch_size: 20
gamma: 0.98
lr: 0.00048
soft_update_tau: 0.005
explore_noise: 0.2
# TD3
update_freq: 2
policy_noise: 0.15
policy_update_gap: 1

# eval
eval_per_rollout: 0.1
eval_steps: null # set with steps per rollout
render: false
render_per_eval: 0.05

curri: {}

# save
cwd: results
rollout_per_save: 0.1