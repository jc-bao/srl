# wandb
wandb: true
project: SAC_debug 
name: default

# seed 
random_seed: 0

# replay
her_rate: 0.8
if_use_per: false
buffer_size: 2500000

# env_params
env_name: 'FrankaPNP-v0'
env_params: null
env_kwargs:
  num_envs: 8192 
reward_scale: 1
extra_info_dim: 0 # extra info get from agent

# network
act_net: ActorFixSAC
critic_net: CriticTwin
net_dim: 128
net_type: deepset
if_act_target: false
if_cri_target: false
gpu_id: 0

# algorithm
agent_name: AgentSAC
max_collect_steps: !!float 1e9
resue: 10
steps_per_rollout: 409600
updates_per_rollout: null # calulate with resue
batch_size: 2048
gamma: 0.98
lr: 0.00024
soft_update_tau: 0.05

# eval
eval_per_rollout: 0.2
eval_steps: null # set with steps per rollout
render: true 

# save
cwd: results
rollout_per_save: 0.1