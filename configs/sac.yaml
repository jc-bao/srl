# wandb
project: debug 
name: hello

# seed 
random_seed: 0

# replay
her_rate: 0.8
if_use_per: False
buffer_size: 1000000

# env_params
env_name: 'PNPToy-v0'
env_params: null
env_kwargs:
  env_num: 1024 
  max_step: 300
  dim: 2
  vel: 0.2 
  err: 0.2
  num_goals: 3
reward_scale: 1
extra_info_dim: 4 # extra info get from agent

# network
act_net: ActorFixSAC
critic_net: CriticREDq
net_dim: 128
net_type: 'deepset'
if_act_target: false
if_cri_target: false
gpu_id: 0

# algorithm
agent_name: AgentREDqSAC
max_collect_steps: 1e9
resue: 20
max_memo: 1000000 
steps_per_rollout: 307200
updates_per_rollout: null # calulate with resue
batch_size: 8192
gamma: 0.99
lr: 0.00024
soft_update_tau: 0.0039

# eval
eval_per_rollout: 1
eval_steps: null # set with steps per rollout

# save
cwd: results