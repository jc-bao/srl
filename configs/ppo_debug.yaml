# wandb
wandb: false
project: debug 
name: hello

# seed 
random_seed: 0

# replay
her_rate: 0.0
if_use_per: False
buffer_size: null 
lambda_entropy: 0.02
lambda_gae_adv: 0.98 
ratio_clip: 0.25
if_use_gae: true

# env_params
env_name: 'FrankaPNP-v0'
env_params: null
env_kwargs:
  num_envs: 2
  num_cameras: 0
  reward_type: dense
  headless: true 
reward_scale: 1

# network
act_net: ActorPPO
critic_net: CriticPPO
net_dim: 128
net_type: 'deepset'
if_act_target: false
if_cri_target: false
gpu_id: 0

# algorithm
agent_name: AgentPPO
max_collect_steps: !!float 1e9
resue: 2
steps_per_rollout: 100
updates_per_rollout: null # calulate with resue
batch_size: 100
gamma: 0.99
lr: 0.00024
soft_update_tau: 0.0039

# eval
eval_per_rollout: 1
eval_steps: null # set with steps per rollout
render: false 

# save
cwd: results
rollout_per_save: 0.0001